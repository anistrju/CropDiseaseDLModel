{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb462f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa58faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\S1130863\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\charset_normalizer\\\\md.cp39-win_amd64.pyd'\n",
      "Check the permissions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.10.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting six>=1.12.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-69.0.2-py3-none-any.whl (819 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.1-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Using cached ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Using cached numpy-1.26.2-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl (100 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, MarkupSafe, importlib-metadata, google-auth, wheel, werkzeug, tensorboard-data-server, six, setuptools, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, packaging, opt-einsum, ml-dtypes, libclang, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --user tensorflow --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef4a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S1130863\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\S1130863\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c88933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "id": "7aab0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('C://Users//S1130863//Downloads/curated_diss_actual/rice_lbwo.xlsx',sheet_name = 'averagefinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "id": "2d47fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = sorted(dataset.loc[:,'Observation Year'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "id": "51370790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1993, 1994, 1995, 1996, 1998, 1999, 2000, 2001]"
      ]
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1762,
   "id": "f22fb55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1993, 1994, 1995, 1996, 1998, 1999, 2000]"
      ]
     },
     "execution_count": 1762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedyears = years[:7]\n",
    "selectedyears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1763,
   "id": "d1689dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 1763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingyear = years[7]\n",
    "testingyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1764,
   "id": "e457ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = dataset[dataset['Observation Year'].isin(selectedyears)]\n",
    "data_test = dataset[dataset['Observation Year'].isin([testingyear])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "id": "3772183a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Observation Year', 'Standard Week', 'maxt', 'mint', 'rh1', 'rh2', 'rf',\n",
       "       'ws', 'ssh', 'evp', 'leafblast', 'gm', 'glh', 'ysb', 'bph', 'cw',\n",
       "       'lfld', 'mrdb', 'lb-bin', 'gm-bin', 'glh-bin', 'ysb-bin', 'oth-bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1765,
   "id": "974338a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.loc[:, ['maxt','mint','rh1','rh2','rf','ws','ssh','evp', 'gm-bin', 'glh-bin', 'ysb-bin']]\n",
    "#X_train_pest = data_train.loc[:,['GM_binary','GLH-binary','YSB-binary','Others-binary']]\n",
    "X_test = data_test.loc[:, ['maxt','mint','rh1','rh2','rf','ws','ssh','evp', 'gm-bin', 'glh-bin', 'ysb-bin']]\n",
    "#X_test_pest = data_test.loc[:,['GM_binary','GLH-binary','YSB-binary','Others-binary']]\n",
    "y_train = data_train.loc[:, ['lb-bin']]\n",
    "y_test = data_test.loc[:, ['lb-bin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ddbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#,'GM_binary','GLH-binary','YSB-binary','Others-binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1766,
   "id": "4320533d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempAvg</th>\n",
       "      <th>RHAvg</th>\n",
       "      <th>NetPrecipitation</th>\n",
       "      <th>ws</th>\n",
       "      <th>ssh</th>\n",
       "      <th>gm-bin</th>\n",
       "      <th>glh-bin</th>\n",
       "      <th>ysb-bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.05</td>\n",
       "      <td>58.15</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.55</td>\n",
       "      <td>45.10</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.25</td>\n",
       "      <td>59.65</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.55</td>\n",
       "      <td>41.50</td>\n",
       "      <td>-9.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.95</td>\n",
       "      <td>50.85</td>\n",
       "      <td>12.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>25.75</td>\n",
       "      <td>71.10</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>25.70</td>\n",
       "      <td>73.95</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>26.20</td>\n",
       "      <td>75.50</td>\n",
       "      <td>16.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>25.85</td>\n",
       "      <td>84.35</td>\n",
       "      <td>67.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>26.65</td>\n",
       "      <td>62.95</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TempAvg  RHAvg  NetPrecipitation    ws   ssh  gm-bin  glh-bin  ysb-bin\n",
       "0      22.05  58.15              -3.8   2.2  10.0       1        0        0\n",
       "1      32.55  45.10              -5.5   5.6  10.6       0        1        1\n",
       "2      23.25  59.65              -2.3   2.7   7.2       0        0        0\n",
       "3      33.55  41.50              -9.2   3.1   8.7       0        0        1\n",
       "4      31.95  50.85              12.6  10.1   9.8       0        1        0\n",
       "..       ...    ...               ...   ...   ...     ...      ...      ...\n",
       "411    25.75  71.10              17.8   3.2   7.7       1        0        1\n",
       "412    25.70  73.95              30.0   3.9   6.2       1        0        1\n",
       "413    26.20  75.50              16.5   3.6   3.3       1        1        1\n",
       "414    25.85  84.35              67.7   5.6   3.0       1        1        1\n",
       "415    26.65  62.95              11.3   1.7   8.9       1        0        1\n",
       "\n",
       "[364 rows x 8 columns]"
      ]
     },
     "execution_count": 1766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['TempAvg'] = (X_train['maxt'] + X_train['mint'])/2\n",
    "X_train['RHAvg'] = (X_train['rh1'] + X_train['rh2'])/2\n",
    "X_train['NetPrecipitation'] = X_train['rf']-X_train['evp']\n",
    "X_train = X_train.loc[:,['TempAvg','RHAvg','NetPrecipitation','ws','ssh',  'gm-bin', 'glh-bin', 'ysb-bin']]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1767,
   "id": "9fab13e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempAvg</th>\n",
       "      <th>RHAvg</th>\n",
       "      <th>NetPrecipitation</th>\n",
       "      <th>ws</th>\n",
       "      <th>ssh</th>\n",
       "      <th>gm-bin</th>\n",
       "      <th>glh-bin</th>\n",
       "      <th>ysb-bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28.850</td>\n",
       "      <td>65.45</td>\n",
       "      <td>58.10</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.800</td>\n",
       "      <td>73.35</td>\n",
       "      <td>6.20</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21.600</td>\n",
       "      <td>63.00</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>22.300</td>\n",
       "      <td>59.55</td>\n",
       "      <td>-4.30</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>22.800</td>\n",
       "      <td>61.85</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>25.250</td>\n",
       "      <td>61.15</td>\n",
       "      <td>-4.40</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>25.250</td>\n",
       "      <td>65.25</td>\n",
       "      <td>-4.20</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>29.150</td>\n",
       "      <td>55.00</td>\n",
       "      <td>61.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>20.050</td>\n",
       "      <td>48.25</td>\n",
       "      <td>-4.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>22.800</td>\n",
       "      <td>47.60</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>28.400</td>\n",
       "      <td>61.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>27.700</td>\n",
       "      <td>63.00</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>21.550</td>\n",
       "      <td>50.05</td>\n",
       "      <td>-4.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>25.300</td>\n",
       "      <td>40.10</td>\n",
       "      <td>-6.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>26.700</td>\n",
       "      <td>78.70</td>\n",
       "      <td>20.40</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>24.150</td>\n",
       "      <td>49.80</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>24.075</td>\n",
       "      <td>70.15</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>25.050</td>\n",
       "      <td>84.10</td>\n",
       "      <td>137.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>26.900</td>\n",
       "      <td>70.85</td>\n",
       "      <td>13.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>26.500</td>\n",
       "      <td>45.95</td>\n",
       "      <td>-6.80</td>\n",
       "      <td>3.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>26.800</td>\n",
       "      <td>52.70</td>\n",
       "      <td>-5.70</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>27.100</td>\n",
       "      <td>51.55</td>\n",
       "      <td>-5.80</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>26.550</td>\n",
       "      <td>80.75</td>\n",
       "      <td>93.90</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>29.300</td>\n",
       "      <td>56.75</td>\n",
       "      <td>9.20</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>29.200</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>29.450</td>\n",
       "      <td>40.95</td>\n",
       "      <td>-7.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>29.450</td>\n",
       "      <td>43.70</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>26.150</td>\n",
       "      <td>72.15</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>27.100</td>\n",
       "      <td>66.50</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>26.000</td>\n",
       "      <td>75.15</td>\n",
       "      <td>25.30</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>25.700</td>\n",
       "      <td>75.85</td>\n",
       "      <td>28.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>23.450</td>\n",
       "      <td>67.30</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>1.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>20.900</td>\n",
       "      <td>64.00</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>22.500</td>\n",
       "      <td>55.25</td>\n",
       "      <td>-4.20</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>31.400</td>\n",
       "      <td>40.00</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>34.050</td>\n",
       "      <td>39.80</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>34.650</td>\n",
       "      <td>34.00</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>4.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>33.050</td>\n",
       "      <td>38.50</td>\n",
       "      <td>-8.70</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>32.100</td>\n",
       "      <td>42.65</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>32.250</td>\n",
       "      <td>43.60</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>26.450</td>\n",
       "      <td>74.45</td>\n",
       "      <td>92.60</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>29.000</td>\n",
       "      <td>60.45</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>28.400</td>\n",
       "      <td>59.85</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>26.650</td>\n",
       "      <td>66.10</td>\n",
       "      <td>6.10</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>28.050</td>\n",
       "      <td>70.45</td>\n",
       "      <td>5.80</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>26.550</td>\n",
       "      <td>80.20</td>\n",
       "      <td>68.10</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>25.400</td>\n",
       "      <td>82.10</td>\n",
       "      <td>89.60</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>25.800</td>\n",
       "      <td>77.30</td>\n",
       "      <td>17.70</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>19.700</td>\n",
       "      <td>51.15</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>1.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>21.050</td>\n",
       "      <td>57.70</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>1.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>20.000</td>\n",
       "      <td>55.50</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>20.900</td>\n",
       "      <td>63.55</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TempAvg  RHAvg  NetPrecipitation   ws   ssh  gm-bin  glh-bin  ysb-bin\n",
       "24    28.850  65.45             58.10  3.2   4.2       0        0        0\n",
       "25    27.800  73.35              6.20  2.3   5.7       0        1        1\n",
       "27    21.600  63.00             -3.40  2.0   7.9       0        1        1\n",
       "29    22.300  59.55             -4.30  3.3   8.3       0        0        1\n",
       "40    22.800  61.85             -3.50  1.9   8.8       1        0        1\n",
       "63    25.250  61.15             -4.40  3.1   8.6       1        0        1\n",
       "81    25.250  65.25             -4.20  3.2   7.8       1        1        0\n",
       "83    29.150  55.00             61.70  2.5   8.3       0        1        1\n",
       "84    20.050  48.25             -4.20  2.0   8.7       0        1        0\n",
       "97    22.800  47.60             -5.50  2.3   9.9       1        0        0\n",
       "98    28.400  61.15              1.00  9.5   8.0       1        0        0\n",
       "99    27.700  63.00             -0.40  8.9   4.1       1        0        0\n",
       "120   21.550  50.05             -4.40  2.0   8.9       1        0        0\n",
       "129   25.300  40.10             -6.10  2.5  10.0       0        0        0\n",
       "143   26.700  78.70             20.40  1.2   4.8       0        1        1\n",
       "156   24.150  49.80             -5.40  2.8  10.1       0        1        0\n",
       "185   24.075  70.15              2.25  1.7   6.5       0        1        0\n",
       "198   25.050  84.10            137.40  2.5   2.6       1        1        1\n",
       "209   26.900  70.85             13.40  2.5   4.9       1        0        1\n",
       "221   26.500  45.95             -6.80  3.4   9.9       0        1        1\n",
       "223   26.800  52.70             -5.70  3.1   7.1       0        1        1\n",
       "227   27.100  51.55             -5.80  3.7   7.5       0        1        1\n",
       "233   26.550  80.75             93.90  1.7   5.1       0        1        1\n",
       "243   29.300  56.75              9.20  3.7   6.0       0        1        1\n",
       "248   29.200  50.00              0.60  3.6   8.3       0        1        1\n",
       "263   29.450  40.95             -7.70  3.0   9.0       0        1        1\n",
       "288   29.450  43.70              2.20  2.5   6.8       0        1        1\n",
       "309   26.150  72.15             -2.50  4.9   3.3       1        0        1\n",
       "310   27.100  66.50             -5.30  4.6   8.0       1        0        1\n",
       "346   26.000  75.15             25.30  1.6   4.7       1        1        1\n",
       "347   25.700  75.85             28.00  2.6   5.6       0        1        1\n",
       "351   23.450  67.30             -3.70  1.9   9.4       0        1        1\n",
       "359   20.900  64.00             -1.90  2.2   5.2       0        0        1\n",
       "360   22.500  55.25             -4.20  2.8   8.7       0        1        0\n",
       "378   31.400  40.00             -7.90  2.2  10.5       0        0        1\n",
       "379   34.050  39.80             -8.50  3.0  10.1       0        0        1\n",
       "380   34.650  34.00            -10.90  4.2   9.9       0        0        0\n",
       "381   33.050  38.50             -8.70  3.5   7.3       0        0        1\n",
       "382   32.100  42.65            -10.00  6.1   9.6       0        0        0\n",
       "383   32.250  43.60             -1.60  7.3   9.6       0        0        0\n",
       "384   26.450  74.45             92.60  9.1   2.6       0        0        0\n",
       "385   29.000  60.45             -6.60  8.6   6.3       0        0        0\n",
       "386   28.400  59.85             -2.70  8.7   5.1       0        0        0\n",
       "387   26.650  66.10              6.10  7.8   2.9       0        0        0\n",
       "389   28.050  70.45              5.80  4.7   5.1       0        0        0\n",
       "390   26.550  80.20             68.10  3.8   3.9       0        0        1\n",
       "392   25.400  82.10             89.60  5.6   2.3       0        0        0\n",
       "402   25.800  77.30             17.70  6.8   3.4       0        0        0\n",
       "403   19.700  51.15             -3.50  1.6  10.1       0        0        0\n",
       "406   21.050  57.70             -3.40  1.7   9.7       0        0        0\n",
       "407   20.000  55.50             -3.30  2.4   8.2       0        0        0\n",
       "408   20.900  63.55             -2.90  1.8   8.3       0        0        0"
      ]
     },
     "execution_count": 1767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['TempAvg'] = (X_test['maxt'] + X_test['mint'])/2\n",
    "X_test['RHAvg'] = (X_test['rh1'] + X_test['rh2'])/2\n",
    "X_test['NetPrecipitation'] = X_test['rf']-X_test['evp']\n",
    "X_test = X_test.loc[:,['TempAvg','RHAvg','NetPrecipitation','ws','ssh', 'gm-bin', 'glh-bin', 'ysb-bin']]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "216c064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1768,
   "id": "90c1132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:,:5] = sc.fit_transform(X_train.iloc[:,:5])\n",
    "X_test.iloc[:,:5] = sc.transform(X_test.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "id": "a5aa5ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:,5:] = sc.fit_transform(X_train.iloc[:,5:])\n",
    "X_test.iloc[:,5:] = sc.transform(X_test.iloc[:,5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1769,
   "id": "c530e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#, 'gm-bin', 'glh-bin', 'ysb-bin', 'oth-bin'\n",
    "X_train['gm-bin'] = X_train['gm-bin'].replace(0,-1)\n",
    "X_train['glh-bin'] = X_train['glh-bin'].replace(0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1770,
   "id": "420d43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['ysb-bin'] = X_train['ysb-bin'].replace(0,-1)\n",
    "#X_train['oth-bin'] = X_train['oth-bin'].replace(0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1771,
   "id": "806f777a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempAvg</th>\n",
       "      <th>RHAvg</th>\n",
       "      <th>NetPrecipitation</th>\n",
       "      <th>ws</th>\n",
       "      <th>ssh</th>\n",
       "      <th>gm-bin</th>\n",
       "      <th>glh-bin</th>\n",
       "      <th>ysb-bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.069890</td>\n",
       "      <td>-0.237408</td>\n",
       "      <td>-0.491960</td>\n",
       "      <td>-0.756888</td>\n",
       "      <td>0.840609</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.672017</td>\n",
       "      <td>-1.290608</td>\n",
       "      <td>-0.545140</td>\n",
       "      <td>0.329558</td>\n",
       "      <td>1.069549</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.756529</td>\n",
       "      <td>-0.116351</td>\n",
       "      <td>-0.445036</td>\n",
       "      <td>-0.597116</td>\n",
       "      <td>-0.227778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.933151</td>\n",
       "      <td>-1.581146</td>\n",
       "      <td>-0.660884</td>\n",
       "      <td>-0.469299</td>\n",
       "      <td>0.344572</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.515336</td>\n",
       "      <td>-0.826555</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>1.767501</td>\n",
       "      <td>0.764295</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>-0.103694</td>\n",
       "      <td>0.807722</td>\n",
       "      <td>0.183738</td>\n",
       "      <td>-0.437345</td>\n",
       "      <td>-0.036995</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-0.116751</td>\n",
       "      <td>1.037731</td>\n",
       "      <td>0.565381</td>\n",
       "      <td>-0.213665</td>\n",
       "      <td>-0.609345</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.013816</td>\n",
       "      <td>1.162823</td>\n",
       "      <td>0.143071</td>\n",
       "      <td>-0.309528</td>\n",
       "      <td>-1.715889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-0.077581</td>\n",
       "      <td>1.877063</td>\n",
       "      <td>1.744723</td>\n",
       "      <td>0.329558</td>\n",
       "      <td>-1.830359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.131326</td>\n",
       "      <td>0.149976</td>\n",
       "      <td>-0.019597</td>\n",
       "      <td>-0.916659</td>\n",
       "      <td>0.420885</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TempAvg     RHAvg  NetPrecipitation        ws       ssh  gm-bin  \\\n",
       "0   -1.069890 -0.237408         -0.491960 -0.756888  0.840609       1   \n",
       "1    1.672017 -1.290608         -0.545140  0.329558  1.069549      -1   \n",
       "2   -0.756529 -0.116351         -0.445036 -0.597116 -0.227778      -1   \n",
       "3    1.933151 -1.581146         -0.660884 -0.469299  0.344572      -1   \n",
       "4    1.515336 -0.826555          0.021070  1.767501  0.764295      -1   \n",
       "..        ...       ...               ...       ...       ...     ...   \n",
       "411 -0.103694  0.807722          0.183738 -0.437345 -0.036995       1   \n",
       "412 -0.116751  1.037731          0.565381 -0.213665 -0.609345       1   \n",
       "413  0.013816  1.162823          0.143071 -0.309528 -1.715889       1   \n",
       "414 -0.077581  1.877063          1.744723  0.329558 -1.830359       1   \n",
       "415  0.131326  0.149976         -0.019597 -0.916659  0.420885       1   \n",
       "\n",
       "     glh-bin  ysb-bin  \n",
       "0         -1       -1  \n",
       "1          1        1  \n",
       "2         -1       -1  \n",
       "3         -1        1  \n",
       "4          1       -1  \n",
       "..       ...      ...  \n",
       "411       -1        1  \n",
       "412       -1        1  \n",
       "413        1        1  \n",
       "414        1        1  \n",
       "415       -1        1  \n",
       "\n",
       "[364 rows x 8 columns]"
      ]
     },
     "execution_count": 1771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1772,
   "id": "a2085f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#, 'gm-bin', 'glh-bin', 'ysb-bin', 'oth-bin'\n",
    "X_test['gm-bin'] = X_test['gm-bin'].replace(0,-1)\n",
    "X_test['glh-bin'] = X_test['glh-bin'].replace(0,-1)\n",
    "\n",
    "X_test['ysb-bin'] = X_test['ysb-bin'].replace(0,-1)\n",
    "#X_test['oth-bin'] = X_test['oth-bin'].replace(0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1773,
   "id": "15794af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempAvg</th>\n",
       "      <th>RHAvg</th>\n",
       "      <th>NetPrecipitation</th>\n",
       "      <th>ws</th>\n",
       "      <th>ssh</th>\n",
       "      <th>gm-bin</th>\n",
       "      <th>glh-bin</th>\n",
       "      <th>ysb-bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.705821</td>\n",
       "      <td>0.351738</td>\n",
       "      <td>1.444413</td>\n",
       "      <td>-0.437345</td>\n",
       "      <td>-1.372479</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.431630</td>\n",
       "      <td>0.989308</td>\n",
       "      <td>-0.179137</td>\n",
       "      <td>-0.724934</td>\n",
       "      <td>-0.800128</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.187400</td>\n",
       "      <td>0.154011</td>\n",
       "      <td>-0.479447</td>\n",
       "      <td>-0.820796</td>\n",
       "      <td>0.039318</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.004606</td>\n",
       "      <td>-0.124421</td>\n",
       "      <td>-0.507601</td>\n",
       "      <td>-0.405391</td>\n",
       "      <td>0.191945</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.874040</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>-0.852751</td>\n",
       "      <td>0.382729</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.234261</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.510729</td>\n",
       "      <td>-0.469299</td>\n",
       "      <td>0.306415</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.234261</td>\n",
       "      <td>0.335597</td>\n",
       "      <td>-0.504473</td>\n",
       "      <td>-0.437345</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.784161</td>\n",
       "      <td>-0.491629</td>\n",
       "      <td>1.557030</td>\n",
       "      <td>-0.661025</td>\n",
       "      <td>0.191945</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.592158</td>\n",
       "      <td>-1.036387</td>\n",
       "      <td>-0.504473</td>\n",
       "      <td>-0.820796</td>\n",
       "      <td>0.344572</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.874040</td>\n",
       "      <td>-1.088846</td>\n",
       "      <td>-0.545140</td>\n",
       "      <td>-0.724934</td>\n",
       "      <td>0.802452</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.588311</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>-0.341805</td>\n",
       "      <td>1.575775</td>\n",
       "      <td>0.077475</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.405517</td>\n",
       "      <td>0.154011</td>\n",
       "      <td>-0.385600</td>\n",
       "      <td>1.384049</td>\n",
       "      <td>-1.410635</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-1.200457</td>\n",
       "      <td>-0.891119</td>\n",
       "      <td>-0.510729</td>\n",
       "      <td>-0.820796</td>\n",
       "      <td>0.420885</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-0.221205</td>\n",
       "      <td>-1.694133</td>\n",
       "      <td>-0.563909</td>\n",
       "      <td>-0.661025</td>\n",
       "      <td>0.840609</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.144383</td>\n",
       "      <td>1.421079</td>\n",
       "      <td>0.265071</td>\n",
       "      <td>-1.076431</td>\n",
       "      <td>-1.143538</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.521509</td>\n",
       "      <td>-0.911295</td>\n",
       "      <td>-0.542011</td>\n",
       "      <td>-0.565162</td>\n",
       "      <td>0.878765</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.541094</td>\n",
       "      <td>0.731052</td>\n",
       "      <td>-0.302702</td>\n",
       "      <td>-0.916659</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.286488</td>\n",
       "      <td>1.856886</td>\n",
       "      <td>3.925098</td>\n",
       "      <td>-0.661025</td>\n",
       "      <td>-1.982985</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.196610</td>\n",
       "      <td>0.787545</td>\n",
       "      <td>0.046096</td>\n",
       "      <td>-0.661025</td>\n",
       "      <td>-1.105382</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.092156</td>\n",
       "      <td>-1.222009</td>\n",
       "      <td>-0.585807</td>\n",
       "      <td>-0.373436</td>\n",
       "      <td>0.802452</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.170496</td>\n",
       "      <td>-0.677250</td>\n",
       "      <td>-0.551396</td>\n",
       "      <td>-0.469299</td>\n",
       "      <td>-0.265935</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.248837</td>\n",
       "      <td>-0.770061</td>\n",
       "      <td>-0.554524</td>\n",
       "      <td>-0.277574</td>\n",
       "      <td>-0.113308</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.105213</td>\n",
       "      <td>1.586525</td>\n",
       "      <td>2.564319</td>\n",
       "      <td>-0.916659</td>\n",
       "      <td>-1.029068</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.823331</td>\n",
       "      <td>-0.350395</td>\n",
       "      <td>-0.085290</td>\n",
       "      <td>-0.277574</td>\n",
       "      <td>-0.685658</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.797218</td>\n",
       "      <td>-0.895154</td>\n",
       "      <td>-0.354318</td>\n",
       "      <td>-0.309528</td>\n",
       "      <td>0.191945</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.862501</td>\n",
       "      <td>-1.625534</td>\n",
       "      <td>-0.613961</td>\n",
       "      <td>-0.501254</td>\n",
       "      <td>0.459042</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.862501</td>\n",
       "      <td>-1.403595</td>\n",
       "      <td>-0.304266</td>\n",
       "      <td>-0.661025</td>\n",
       "      <td>-0.380405</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.892462</td>\n",
       "      <td>-0.451293</td>\n",
       "      <td>0.105878</td>\n",
       "      <td>-1.715889</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.248837</td>\n",
       "      <td>0.436479</td>\n",
       "      <td>-0.538883</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.077475</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.038411</td>\n",
       "      <td>1.134577</td>\n",
       "      <td>0.418355</td>\n",
       "      <td>-0.948614</td>\n",
       "      <td>-1.181695</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-0.116751</td>\n",
       "      <td>1.191070</td>\n",
       "      <td>0.502817</td>\n",
       "      <td>-0.629071</td>\n",
       "      <td>-0.838285</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.704302</td>\n",
       "      <td>0.501043</td>\n",
       "      <td>-0.488831</td>\n",
       "      <td>-0.852751</td>\n",
       "      <td>0.611669</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>-1.370194</td>\n",
       "      <td>0.234716</td>\n",
       "      <td>-0.432523</td>\n",
       "      <td>-0.756888</td>\n",
       "      <td>-0.990912</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>-0.952380</td>\n",
       "      <td>-0.471453</td>\n",
       "      <td>-0.504473</td>\n",
       "      <td>-0.565162</td>\n",
       "      <td>0.344572</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>1.371713</td>\n",
       "      <td>-1.702204</td>\n",
       "      <td>-0.620217</td>\n",
       "      <td>-0.756888</td>\n",
       "      <td>1.031392</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2.063718</td>\n",
       "      <td>-1.718345</td>\n",
       "      <td>-0.638986</td>\n",
       "      <td>-0.501254</td>\n",
       "      <td>0.878765</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2.220398</td>\n",
       "      <td>-2.186434</td>\n",
       "      <td>-0.714064</td>\n",
       "      <td>-0.117802</td>\n",
       "      <td>0.802452</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1.802584</td>\n",
       "      <td>-1.823261</td>\n",
       "      <td>-0.645243</td>\n",
       "      <td>-0.341482</td>\n",
       "      <td>-0.189622</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>1.554506</td>\n",
       "      <td>-1.488335</td>\n",
       "      <td>-0.685910</td>\n",
       "      <td>0.489329</td>\n",
       "      <td>0.687982</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1.593676</td>\n",
       "      <td>-1.411666</td>\n",
       "      <td>-0.423139</td>\n",
       "      <td>0.872781</td>\n",
       "      <td>0.687982</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.079099</td>\n",
       "      <td>1.078083</td>\n",
       "      <td>2.523652</td>\n",
       "      <td>1.447958</td>\n",
       "      <td>-1.982985</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.744991</td>\n",
       "      <td>-0.051787</td>\n",
       "      <td>-0.579550</td>\n",
       "      <td>1.288186</td>\n",
       "      <td>-0.571188</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.588311</td>\n",
       "      <td>-0.100210</td>\n",
       "      <td>-0.457549</td>\n",
       "      <td>1.320141</td>\n",
       "      <td>-1.029068</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.131326</td>\n",
       "      <td>0.404197</td>\n",
       "      <td>-0.182265</td>\n",
       "      <td>1.032552</td>\n",
       "      <td>-1.868515</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.755263</td>\n",
       "      <td>-0.191650</td>\n",
       "      <td>0.041969</td>\n",
       "      <td>-1.029068</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.105213</td>\n",
       "      <td>1.542137</td>\n",
       "      <td>1.757236</td>\n",
       "      <td>-0.245619</td>\n",
       "      <td>-1.486949</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>-0.195091</td>\n",
       "      <td>1.695476</td>\n",
       "      <td>2.429805</td>\n",
       "      <td>0.329558</td>\n",
       "      <td>-2.097455</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>-0.090638</td>\n",
       "      <td>1.308092</td>\n",
       "      <td>0.180609</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>-1.677732</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-1.683555</td>\n",
       "      <td>-0.802343</td>\n",
       "      <td>-0.482575</td>\n",
       "      <td>-0.948614</td>\n",
       "      <td>0.878765</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-1.331024</td>\n",
       "      <td>-0.273725</td>\n",
       "      <td>-0.479447</td>\n",
       "      <td>-0.916659</td>\n",
       "      <td>0.726139</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-1.605215</td>\n",
       "      <td>-0.451276</td>\n",
       "      <td>-0.476319</td>\n",
       "      <td>-0.692979</td>\n",
       "      <td>0.153789</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-1.370194</td>\n",
       "      <td>0.198399</td>\n",
       "      <td>-0.463806</td>\n",
       "      <td>-0.884705</td>\n",
       "      <td>0.191945</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TempAvg     RHAvg  NetPrecipitation        ws       ssh  gm-bin  \\\n",
       "24   0.705821  0.351738          1.444413 -0.437345 -1.372479      -1   \n",
       "25   0.431630  0.989308         -0.179137 -0.724934 -0.800128      -1   \n",
       "27  -1.187400  0.154011         -0.479447 -0.820796  0.039318      -1   \n",
       "29  -1.004606 -0.124421         -0.507601 -0.405391  0.191945      -1   \n",
       "40  -0.874040  0.061200         -0.482575 -0.852751  0.382729       1   \n",
       "63  -0.234261  0.004707         -0.510729 -0.469299  0.306415       1   \n",
       "81  -0.234261  0.335597         -0.504473 -0.437345  0.001162       1   \n",
       "83   0.784161 -0.491629          1.557030 -0.661025  0.191945      -1   \n",
       "84  -1.592158 -1.036387         -0.504473 -0.820796  0.344572      -1   \n",
       "97  -0.874040 -1.088846         -0.545140 -0.724934  0.802452       1   \n",
       "98   0.588311  0.004707         -0.341805  1.575775  0.077475       1   \n",
       "99   0.405517  0.154011         -0.385600  1.384049 -1.410635       1   \n",
       "120 -1.200457 -0.891119         -0.510729 -0.820796  0.420885       1   \n",
       "129 -0.221205 -1.694133         -0.563909 -0.661025  0.840609      -1   \n",
       "143  0.144383  1.421079          0.265071 -1.076431 -1.143538      -1   \n",
       "156 -0.521509 -0.911295         -0.542011 -0.565162  0.878765      -1   \n",
       "185 -0.541094  0.731052         -0.302702 -0.916659 -0.494875      -1   \n",
       "198 -0.286488  1.856886          3.925098 -0.661025 -1.982985       1   \n",
       "209  0.196610  0.787545          0.046096 -0.661025 -1.105382       1   \n",
       "221  0.092156 -1.222009         -0.585807 -0.373436  0.802452      -1   \n",
       "223  0.170496 -0.677250         -0.551396 -0.469299 -0.265935      -1   \n",
       "227  0.248837 -0.770061         -0.554524 -0.277574 -0.113308      -1   \n",
       "233  0.105213  1.586525          2.564319 -0.916659 -1.029068      -1   \n",
       "243  0.823331 -0.350395         -0.085290 -0.277574 -0.685658      -1   \n",
       "248  0.797218 -0.895154         -0.354318 -0.309528  0.191945      -1   \n",
       "263  0.862501 -1.625534         -0.613961 -0.501254  0.459042      -1   \n",
       "288  0.862501 -1.403595         -0.304266 -0.661025 -0.380405      -1   \n",
       "309  0.000759  0.892462         -0.451293  0.105878 -1.715889       1   \n",
       "310  0.248837  0.436479         -0.538883  0.010015  0.077475       1   \n",
       "346 -0.038411  1.134577          0.418355 -0.948614 -1.181695       1   \n",
       "347 -0.116751  1.191070          0.502817 -0.629071 -0.838285      -1   \n",
       "351 -0.704302  0.501043         -0.488831 -0.852751  0.611669      -1   \n",
       "359 -1.370194  0.234716         -0.432523 -0.756888 -0.990912      -1   \n",
       "360 -0.952380 -0.471453         -0.504473 -0.565162  0.344572      -1   \n",
       "378  1.371713 -1.702204         -0.620217 -0.756888  1.031392      -1   \n",
       "379  2.063718 -1.718345         -0.638986 -0.501254  0.878765      -1   \n",
       "380  2.220398 -2.186434         -0.714064 -0.117802  0.802452      -1   \n",
       "381  1.802584 -1.823261         -0.645243 -0.341482 -0.189622      -1   \n",
       "382  1.554506 -1.488335         -0.685910  0.489329  0.687982      -1   \n",
       "383  1.593676 -1.411666         -0.423139  0.872781  0.687982      -1   \n",
       "384  0.079099  1.078083          2.523652  1.447958 -1.982985      -1   \n",
       "385  0.744991 -0.051787         -0.579550  1.288186 -0.571188      -1   \n",
       "386  0.588311 -0.100210         -0.457549  1.320141 -1.029068      -1   \n",
       "387  0.131326  0.404197         -0.182265  1.032552 -1.868515      -1   \n",
       "389  0.496914  0.755263         -0.191650  0.041969 -1.029068      -1   \n",
       "390  0.105213  1.542137          1.757236 -0.245619 -1.486949      -1   \n",
       "392 -0.195091  1.695476          2.429805  0.329558 -2.097455      -1   \n",
       "402 -0.090638  1.308092          0.180609  0.713009 -1.677732      -1   \n",
       "403 -1.683555 -0.802343         -0.482575 -0.948614  0.878765      -1   \n",
       "406 -1.331024 -0.273725         -0.479447 -0.916659  0.726139      -1   \n",
       "407 -1.605215 -0.451276         -0.476319 -0.692979  0.153789      -1   \n",
       "408 -1.370194  0.198399         -0.463806 -0.884705  0.191945      -1   \n",
       "\n",
       "     glh-bin  ysb-bin  \n",
       "24        -1       -1  \n",
       "25         1        1  \n",
       "27         1        1  \n",
       "29        -1        1  \n",
       "40        -1        1  \n",
       "63        -1        1  \n",
       "81         1       -1  \n",
       "83         1        1  \n",
       "84         1       -1  \n",
       "97        -1       -1  \n",
       "98        -1       -1  \n",
       "99        -1       -1  \n",
       "120       -1       -1  \n",
       "129       -1       -1  \n",
       "143        1        1  \n",
       "156        1       -1  \n",
       "185        1       -1  \n",
       "198        1        1  \n",
       "209       -1        1  \n",
       "221        1        1  \n",
       "223        1        1  \n",
       "227        1        1  \n",
       "233        1        1  \n",
       "243        1        1  \n",
       "248        1        1  \n",
       "263        1        1  \n",
       "288        1        1  \n",
       "309       -1        1  \n",
       "310       -1        1  \n",
       "346        1        1  \n",
       "347        1        1  \n",
       "351        1        1  \n",
       "359       -1        1  \n",
       "360        1       -1  \n",
       "378       -1        1  \n",
       "379       -1        1  \n",
       "380       -1       -1  \n",
       "381       -1        1  \n",
       "382       -1       -1  \n",
       "383       -1       -1  \n",
       "384       -1       -1  \n",
       "385       -1       -1  \n",
       "386       -1       -1  \n",
       "387       -1       -1  \n",
       "389       -1       -1  \n",
       "390       -1        1  \n",
       "392       -1       -1  \n",
       "402       -1       -1  \n",
       "403       -1       -1  \n",
       "406       -1       -1  \n",
       "407       -1       -1  \n",
       "408       -1       -1  "
      ]
     },
     "execution_count": 1773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8cd166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1774,
   "id": "29e10016",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "05393240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.add(tf.keras.layers.Dropout(0.4,input_shape=(9,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1775,
   "id": "ed9d81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu',kernel_initializer=initializers.Ones()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb3a3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.add(tf.keras.layers.Dropout(0.2,input_shape=(6,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1776,
   "id": "acf61153",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu',kernel_initializer=initializers.Ones()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1777,
   "id": "8703174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid',kernel_initializer=initializers.Ones()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1778,
   "id": "1b4cae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1779,
   "id": "4a9e2ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.0181 - accuracy: 0.6786\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4903 - accuracy: 0.6786\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9914 - accuracy: 0.6786\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.4756 - accuracy: 0.6813\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.9889 - accuracy: 0.6896\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 17.5385 - accuracy: 0.6923\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.0910 - accuracy: 0.6978\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.6515 - accuracy: 0.7005\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.2439 - accuracy: 0.7033\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8391 - accuracy: 0.7115\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4315 - accuracy: 0.7115\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.0633 - accuracy: 0.7143\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.7112 - accuracy: 0.7198\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3541 - accuracy: 0.7198\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.0143 - accuracy: 0.7253\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6777 - accuracy: 0.7253\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.3480 - accuracy: 0.7280\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.0388 - accuracy: 0.7335\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.7234 - accuracy: 0.7390\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4405 - accuracy: 0.7390\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1553 - accuracy: 0.7390\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8934 - accuracy: 0.7445\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.6053 - accuracy: 0.7445\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.3483 - accuracy: 0.7500\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0929 - accuracy: 0.7527\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8656 - accuracy: 0.7527\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.6131 - accuracy: 0.7555\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3912 - accuracy: 0.7555\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.1622 - accuracy: 0.7582\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9354 - accuracy: 0.7610\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.7061 - accuracy: 0.7637\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.5145 - accuracy: 0.7637\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.3045 - accuracy: 0.7637\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.1014 - accuracy: 0.7692\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.9103 - accuracy: 0.7692\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7180 - accuracy: 0.7692\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5318 - accuracy: 0.7692\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.3547 - accuracy: 0.7720\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1725 - accuracy: 0.7720\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0073 - accuracy: 0.7720\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8300 - accuracy: 0.7720\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.6662 - accuracy: 0.7747\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.5082 - accuracy: 0.7747\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3540 - accuracy: 0.7775\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2024 - accuracy: 0.7775\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.0496 - accuracy: 0.7747\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.9031 - accuracy: 0.7775\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7555 - accuracy: 0.7775\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6125 - accuracy: 0.7747\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4850 - accuracy: 0.7747\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3452 - accuracy: 0.7775\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2187 - accuracy: 0.7775\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.0840 - accuracy: 0.7775\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9563 - accuracy: 0.7802\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.8403 - accuracy: 0.7830\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7127 - accuracy: 0.7830\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6006 - accuracy: 0.7830\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4876 - accuracy: 0.7830\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3764 - accuracy: 0.7857\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2637 - accuracy: 0.7857\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1527 - accuracy: 0.7857\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0415 - accuracy: 0.7857\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9470 - accuracy: 0.7857\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8473 - accuracy: 0.7857\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7512 - accuracy: 0.7857\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6525 - accuracy: 0.7857\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5545 - accuracy: 0.7857\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4590 - accuracy: 0.7857\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3783 - accuracy: 0.7885\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2849 - accuracy: 0.7912\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1958 - accuracy: 0.7857\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1180 - accuracy: 0.7857\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0342 - accuracy: 0.7857\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9486 - accuracy: 0.7857\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8687 - accuracy: 0.7857\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7947 - accuracy: 0.7857\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7188 - accuracy: 0.7857\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6458 - accuracy: 0.7857\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5655 - accuracy: 0.7857\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.4955 - accuracy: 0.7885\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4313 - accuracy: 0.7885\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3560 - accuracy: 0.7885\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2932 - accuracy: 0.7940\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2263 - accuracy: 0.7940\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1649 - accuracy: 0.7940\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0954 - accuracy: 0.7912\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0404 - accuracy: 0.7912\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9810 - accuracy: 0.7912\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9218 - accuracy: 0.7912\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8654 - accuracy: 0.7940\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8091 - accuracy: 0.7940\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7559 - accuracy: 0.7940\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7001 - accuracy: 0.7940\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6496 - accuracy: 0.7940\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5953 - accuracy: 0.7967\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5490 - accuracy: 0.7967\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4977 - accuracy: 0.8022\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4524 - accuracy: 0.8022\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4037 - accuracy: 0.8022\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3580 - accuracy: 0.8022\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3146 - accuracy: 0.8022\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2698 - accuracy: 0.8022\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2252 - accuracy: 0.8049\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1852 - accuracy: 0.8049\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1444 - accuracy: 0.8077\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1029 - accuracy: 0.8077\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0657 - accuracy: 0.8104\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0250 - accuracy: 0.8104\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9869 - accuracy: 0.8132\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9511 - accuracy: 0.8132\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9155 - accuracy: 0.8132\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8787 - accuracy: 0.8132\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8470 - accuracy: 0.8132\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8105 - accuracy: 0.8132\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7801 - accuracy: 0.8132\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7468 - accuracy: 0.8132\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7129 - accuracy: 0.8132\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6845 - accuracy: 0.8132\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6540 - accuracy: 0.8132\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6236 - accuracy: 0.8132\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5959 - accuracy: 0.8132\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5658 - accuracy: 0.8132\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5379 - accuracy: 0.8132\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5129 - accuracy: 0.8132\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4861 - accuracy: 0.8159\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4590 - accuracy: 0.8187\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4344 - accuracy: 0.8187\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4083 - accuracy: 0.8187\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3871 - accuracy: 0.8187\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3633 - accuracy: 0.8187\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3383 - accuracy: 0.8214\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3159 - accuracy: 0.8214\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2959 - accuracy: 0.8214\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2734 - accuracy: 0.8242\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2520 - accuracy: 0.8269\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2315 - accuracy: 0.8214\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2140 - accuracy: 0.8187\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1934 - accuracy: 0.8159\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1749 - accuracy: 0.8159\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1551 - accuracy: 0.8159\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1378 - accuracy: 0.8159\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1209 - accuracy: 0.8159\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1038 - accuracy: 0.8159\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.8187\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0703 - accuracy: 0.8187\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0539 - accuracy: 0.8214\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0393 - accuracy: 0.8214\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0242 - accuracy: 0.8214\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0100 - accuracy: 0.8242\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9938 - accuracy: 0.8269\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9806 - accuracy: 0.8269\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9661 - accuracy: 0.8269\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9511 - accuracy: 0.8269\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9375 - accuracy: 0.8297\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9257 - accuracy: 0.8297\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9111 - accuracy: 0.8297\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8991 - accuracy: 0.8297\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8870 - accuracy: 0.8297\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8738 - accuracy: 0.8297\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8616 - accuracy: 0.8297\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8499 - accuracy: 0.8269\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8394 - accuracy: 0.8214\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8288 - accuracy: 0.8214\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8170 - accuracy: 0.8242\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8068 - accuracy: 0.8242\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7960 - accuracy: 0.8269\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7866 - accuracy: 0.8269\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.8269\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7676 - accuracy: 0.8269\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.8269\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.8352\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.8324\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.8352\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7234 - accuracy: 0.8352\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7147 - accuracy: 0.8379\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.8379\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.8379\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.8379\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.8379\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.8352\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.8379\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.8379\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.8407\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.8434\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.8516\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.8516\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.8544\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.8544\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.8544\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.8544\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.8544\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.8544\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.8571\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.8571\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.8599\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.8599\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.8599\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.8599\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.8599\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29d61e0e430>"
      ]
     },
     "execution_count": 1779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 52, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1780,
   "id": "151e38dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1781,
   "id": "f3563da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  1]\n",
      " [ 0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9807692307692307"
      ]
     },
     "execution_count": 1781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "id": "397aa50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "488bfb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.layers.LeakyReLU(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "f04db405",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "c984ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.4872\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.5256\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.5449\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.5673\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.5929\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6026\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6250\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6346\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6571\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6827\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.6923\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7179\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7372\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7564\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7692\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7853\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7885\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7949\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7949\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7949\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8013\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7981\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8077\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8141\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8205\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8269\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8333\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8365\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8365\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8429\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8397\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8429\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8429\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8462\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8429\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8462\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8462\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8494\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8526\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8526\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8526\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8590\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8590\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8590\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.8590\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8590\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8622\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8622\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8622\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "[[87  5]\n",
      " [ 9  3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, batch_size = 52, epochs = 50)\n",
    "\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3f180",
   "metadata": {},
   "source": [
    "### We shall do ANN on purely pest based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0bc55638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pest = data_train.loc[:,['GM_binary','GLH-binary','YSB-binary','Others-binary']]\n",
    "X_test_pest = data_test.loc[:,['GM_binary','GLH-binary','YSB-binary','Others-binary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "88892881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.7949\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.8237\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.8269\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.8269\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.8269\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.8269\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.8269\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.8269\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.8269\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.8269\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.8269\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.8269\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.8269\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.8269\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.8269\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.8269\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.8269\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.8269\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8269\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8269\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8269\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8269\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8269\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8269\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8269\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8269\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8269\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8269\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8269\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8269\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8269\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8269\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8269\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8269\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8269\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8269\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8269\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8269\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8269\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8269\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8269\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8269\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8269\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8269\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8269\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8269\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8269\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8269\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8269\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8269\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8365\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8365\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8365\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8365\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8365\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8365\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8365\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8365\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8365\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8365\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8365\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8365\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8365\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8365\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8365\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8365\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8365\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8365\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8365\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3141 - accuracy: 0.8365\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8494\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8590\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8590\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8590\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8590\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8590\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8590\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8590\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8590\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8590\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8590\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8590\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8590\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8590\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8590\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8590\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8590\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8590\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8590\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8590\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8590\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8590\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8590\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8590\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8590\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8590\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8590\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8590\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eeef56c370>"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ann.fit(X_train_pest, y_train, batch_size = 52, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "0ebdd640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "[[89  3]\n",
      " [ 1 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9615384615384616"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test_pest)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5cf0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83b6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ccd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68724898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "14ca709b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempAvg</th>\n",
       "      <th>RHDiff</th>\n",
       "      <th>Water</th>\n",
       "      <th>WS</th>\n",
       "      <th>SSH</th>\n",
       "      <th>GM_binary</th>\n",
       "      <th>GLH-binary</th>\n",
       "      <th>YSB-binary</th>\n",
       "      <th>Others-binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-1.399216</td>\n",
       "      <td>1.081226</td>\n",
       "      <td>-0.479691</td>\n",
       "      <td>-0.937585</td>\n",
       "      <td>0.575039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.983891</td>\n",
       "      <td>1.089956</td>\n",
       "      <td>-0.479691</td>\n",
       "      <td>-0.906697</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.958201</td>\n",
       "      <td>1.663255</td>\n",
       "      <td>-0.489083</td>\n",
       "      <td>-0.865513</td>\n",
       "      <td>0.677860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.906821</td>\n",
       "      <td>1.578861</td>\n",
       "      <td>-0.502649</td>\n",
       "      <td>-0.783145</td>\n",
       "      <td>0.587892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-1.112342</td>\n",
       "      <td>1.721458</td>\n",
       "      <td>-0.500562</td>\n",
       "      <td>-0.886105</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>-1.180849</td>\n",
       "      <td>0.857144</td>\n",
       "      <td>-0.480735</td>\n",
       "      <td>-0.855217</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-1.668963</td>\n",
       "      <td>1.284936</td>\n",
       "      <td>-0.483865</td>\n",
       "      <td>-0.978769</td>\n",
       "      <td>0.883501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>-1.322145</td>\n",
       "      <td>1.363510</td>\n",
       "      <td>-0.480735</td>\n",
       "      <td>-0.947881</td>\n",
       "      <td>0.729270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-1.591892</td>\n",
       "      <td>1.049214</td>\n",
       "      <td>-0.477604</td>\n",
       "      <td>-0.731666</td>\n",
       "      <td>0.150904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-1.360681</td>\n",
       "      <td>0.603961</td>\n",
       "      <td>-0.465081</td>\n",
       "      <td>-0.916993</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TempAvg    RHDiff     Water        WS       SSH  GM_binary  GLH-binary  \\\n",
       "73  -1.399216  1.081226 -0.479691 -0.937585  0.575039          0           0   \n",
       "74  -0.983891  1.089956 -0.479691 -0.906697  0.716418          0           0   \n",
       "75  -0.958201  1.663255 -0.489083 -0.865513  0.677860          0           0   \n",
       "76  -0.906821  1.578861 -0.502649 -0.783145  0.587892          0           0   \n",
       "77  -1.112342  1.721458 -0.500562 -0.886105  0.844944          0           0   \n",
       "..        ...       ...       ...       ...       ...        ...         ...   \n",
       "411 -1.180849  0.857144 -0.480735 -0.855217  0.035231          0           0   \n",
       "412 -1.668963  1.284936 -0.483865 -0.978769  0.883501          0           0   \n",
       "413 -1.322145  1.363510 -0.480735 -0.947881  0.729270          0           0   \n",
       "414 -1.591892  1.049214 -0.477604 -0.731666  0.150904          0           0   \n",
       "415 -1.360681  0.603961 -0.465081 -0.916993  0.189462          0           0   \n",
       "\n",
       "     YSB-binary  Others-binary  \n",
       "73            0              0  \n",
       "74            0              0  \n",
       "75            0              0  \n",
       "76            0              0  \n",
       "77            1              0  \n",
       "..          ...            ...  \n",
       "411           1              1  \n",
       "412           0              1  \n",
       "413           0              1  \n",
       "414           0              0  \n",
       "415           0              0  \n",
       "\n",
       "[104 rows x 9 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3891c56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4b475aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 3ms/step - loss: 0.7404 - accuracy: 0.5417\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.5577\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.5481\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.5353\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7051\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.7340\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.7628\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.7692\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.8013\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.8013\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.8013\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.8173\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.8269\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.8269\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.8269\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.8269\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.8269\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.8269\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.8269\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.8269\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.8269\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8269\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8269\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8269\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8269\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8269\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8269\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8269\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8269\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8269\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8269\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8269\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8269\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8269\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8269\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8269\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8269\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8462\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8462\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8462\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8462\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8462\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8462\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8462\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8462\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8462\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8462\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8462\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8462\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8462\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8462\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8462\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8462\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8462\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8494\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8558\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8558\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8558\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8558\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8558\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8558\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8558\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8558\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8558\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8558\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8558\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8590\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8686\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8494\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8686\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8686\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8686\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8686\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8686\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8686\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8686\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8686\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8686\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8686\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8686\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8686\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8686\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8686\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8686\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8686\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8686\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8686\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8686\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8686\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8686\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8686\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8686\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8686\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8686\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8686\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8686\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eeecab7b50>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ann.fit(X_train_pest, y_train, batch_size = 26, epochs = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e0db7bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "[[82 10]\n",
      " [10  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8076923076923077"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d3fea67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7586206896551724"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9405eee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_result_pestnn = ann.predict(X_train_pest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4b9451ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result_pestnn = (y_result_pestnn>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bc2a4228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235  23]\n",
      " [ 18  36]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_train, y_result_pestnn)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5e537ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8685897435897436"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,y_result_pestnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "743cd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Pest_NN_Res'] = y_result_pestnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "55f487f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAXT</th>\n",
       "      <th>MINT</th>\n",
       "      <th>RH1</th>\n",
       "      <th>RH2</th>\n",
       "      <th>RF</th>\n",
       "      <th>WS</th>\n",
       "      <th>SSH</th>\n",
       "      <th>EVP</th>\n",
       "      <th>Pest_NN_Res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>75.9</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>72.6</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.7</td>\n",
       "      <td>13.1</td>\n",
       "      <td>75.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>12.7</td>\n",
       "      <td>76.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>28.6</td>\n",
       "      <td>22.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>31.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80.1</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>31.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>93.6</td>\n",
       "      <td>60.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>31.1</td>\n",
       "      <td>22.9</td>\n",
       "      <td>89.6</td>\n",
       "      <td>60.6</td>\n",
       "      <td>14.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>31.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>92.3</td>\n",
       "      <td>52.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAXT  MINT   RH1   RH2    RF   WS   SSH  EVP  Pest_NN_Res\n",
       "0    29.1  12.8  75.9  29.6   0.0  2.1   9.6  3.2        False\n",
       "1    31.1  13.1  72.6  27.3   0.0  1.7  10.2  3.2        False\n",
       "2    30.7  13.1  75.3  28.3   0.0  1.8   9.9  3.0        False\n",
       "3    30.3  11.4  74.0  29.6   0.0  1.7   9.9  3.1        False\n",
       "4    30.5  12.7  76.3  27.1   0.0  2.2  10.0  3.1        False\n",
       "..    ...   ...   ...   ...   ...  ...   ...  ...          ...\n",
       "357  28.6  22.8  87.0  67.0   1.9  5.4   4.4  3.4         True\n",
       "358  31.4  23.0  80.1  52.6   1.8  4.4   7.0  5.3         True\n",
       "359  31.7  23.1  93.6  60.4  23.4  1.9   5.7  2.9         True\n",
       "360  31.1  22.9  89.6  60.6  14.6  3.0   8.6  3.7         True\n",
       "361  31.5  22.4  92.3  52.3   8.4  2.3   7.4  3.6         True\n",
       "\n",
       "[312 rows x 9 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f57d6801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAXT</th>\n",
       "      <th>MINT</th>\n",
       "      <th>RH1</th>\n",
       "      <th>RH2</th>\n",
       "      <th>RF</th>\n",
       "      <th>WS</th>\n",
       "      <th>SSH</th>\n",
       "      <th>EVP</th>\n",
       "      <th>Pest_NN_Res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>75.9</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>72.6</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.7</td>\n",
       "      <td>13.1</td>\n",
       "      <td>75.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>12.7</td>\n",
       "      <td>76.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>28.6</td>\n",
       "      <td>22.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>31.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80.1</td>\n",
       "      <td>52.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>31.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>93.6</td>\n",
       "      <td>60.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>31.1</td>\n",
       "      <td>22.9</td>\n",
       "      <td>89.6</td>\n",
       "      <td>60.6</td>\n",
       "      <td>14.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>31.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>92.3</td>\n",
       "      <td>52.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAXT  MINT   RH1   RH2    RF   WS   SSH  EVP  Pest_NN_Res\n",
       "0    29.1  12.8  75.9  29.6   0.0  2.1   9.6  3.2            0\n",
       "1    31.1  13.1  72.6  27.3   0.0  1.7  10.2  3.2            0\n",
       "2    30.7  13.1  75.3  28.3   0.0  1.8   9.9  3.0            0\n",
       "3    30.3  11.4  74.0  29.6   0.0  1.7   9.9  3.1            0\n",
       "4    30.5  12.7  76.3  27.1   0.0  2.2  10.0  3.1            0\n",
       "..    ...   ...   ...   ...   ...  ...   ...  ...          ...\n",
       "357  28.6  22.8  87.0  67.0   1.9  5.4   4.4  3.4            1\n",
       "358  31.4  23.0  80.1  52.6   1.8  4.4   7.0  5.3            1\n",
       "359  31.7  23.1  93.6  60.4  23.4  1.9   5.7  2.9            1\n",
       "360  31.1  22.9  89.6  60.6  14.6  3.0   8.6  3.7            1\n",
       "361  31.5  22.4  92.3  52.3   8.4  2.3   7.4  3.6            1\n",
       "\n",
       "[312 rows x 9 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X_train.iloc[:,8] = le.fit_transform(X_train.iloc[:, 8])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "885067a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Pest_NN_Res'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c225123a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAXT</th>\n",
       "      <th>MINT</th>\n",
       "      <th>RH1</th>\n",
       "      <th>RH2</th>\n",
       "      <th>RF</th>\n",
       "      <th>WS</th>\n",
       "      <th>SSH</th>\n",
       "      <th>EVP</th>\n",
       "      <th>Pest_NN_Res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.962261</td>\n",
       "      <td>-1.503431</td>\n",
       "      <td>0.234385</td>\n",
       "      <td>-0.602145</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.937585</td>\n",
       "      <td>0.575039</td>\n",
       "      <td>-0.668809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.522708</td>\n",
       "      <td>-1.189568</td>\n",
       "      <td>0.411588</td>\n",
       "      <td>-0.489812</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.906697</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>-0.668809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.323665</td>\n",
       "      <td>-1.317966</td>\n",
       "      <td>0.387146</td>\n",
       "      <td>-0.908507</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.865513</td>\n",
       "      <td>0.677860</td>\n",
       "      <td>-0.557126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.365132</td>\n",
       "      <td>-1.196701</td>\n",
       "      <td>0.594901</td>\n",
       "      <td>-0.710393</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.783145</td>\n",
       "      <td>0.587892</td>\n",
       "      <td>-0.395805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.414893</td>\n",
       "      <td>-1.496298</td>\n",
       "      <td>0.546017</td>\n",
       "      <td>-0.843150</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.886105</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>-0.420623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>-0.837859</td>\n",
       "      <td>-1.246634</td>\n",
       "      <td>0.637674</td>\n",
       "      <td>-0.175280</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.855217</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>-0.656400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-0.663697</td>\n",
       "      <td>-2.209623</td>\n",
       "      <td>-0.223898</td>\n",
       "      <td>-1.051476</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.978769</td>\n",
       "      <td>0.883501</td>\n",
       "      <td>-0.619172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>-0.514414</td>\n",
       "      <td>-1.760228</td>\n",
       "      <td>0.417698</td>\n",
       "      <td>-0.677714</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.947881</td>\n",
       "      <td>0.729270</td>\n",
       "      <td>-0.656400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-1.036903</td>\n",
       "      <td>-1.760228</td>\n",
       "      <td>0.051072</td>\n",
       "      <td>-0.702223</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.731666</td>\n",
       "      <td>0.150904</td>\n",
       "      <td>-0.693628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-1.012022</td>\n",
       "      <td>-1.396432</td>\n",
       "      <td>0.555183</td>\n",
       "      <td>-0.052735</td>\n",
       "      <td>-0.543958</td>\n",
       "      <td>-0.916993</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>-0.842539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAXT      MINT       RH1       RH2        RF        WS       SSH  \\\n",
       "73  -0.962261 -1.503431  0.234385 -0.602145 -0.543958 -0.937585  0.575039   \n",
       "74  -0.522708 -1.189568  0.411588 -0.489812 -0.543958 -0.906697  0.716418   \n",
       "75  -0.323665 -1.317966  0.387146 -0.908507 -0.543958 -0.865513  0.677860   \n",
       "76  -0.365132 -1.196701  0.594901 -0.710393 -0.543958 -0.783145  0.587892   \n",
       "77  -0.414893 -1.496298  0.546017 -0.843150 -0.543958 -0.886105  0.844944   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "411 -0.837859 -1.246634  0.637674 -0.175280 -0.543958 -0.855217  0.035231   \n",
       "412 -0.663697 -2.209623 -0.223898 -1.051476 -0.543958 -0.978769  0.883501   \n",
       "413 -0.514414 -1.760228  0.417698 -0.677714 -0.543958 -0.947881  0.729270   \n",
       "414 -1.036903 -1.760228  0.051072 -0.702223 -0.543958 -0.731666  0.150904   \n",
       "415 -1.012022 -1.396432  0.555183 -0.052735 -0.543958 -0.916993  0.189462   \n",
       "\n",
       "          EVP  Pest_NN_Res  \n",
       "73  -0.668809            0  \n",
       "74  -0.668809            0  \n",
       "75  -0.557126            0  \n",
       "76  -0.395805            0  \n",
       "77  -0.420623            0  \n",
       "..        ...          ...  \n",
       "411 -0.656400            0  \n",
       "412 -0.619172            0  \n",
       "413 -0.656400            0  \n",
       "414 -0.693628            0  \n",
       "415 -0.842539            0  \n",
       "\n",
       "[104 rows x 9 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "X_test.iloc[:,8] = le.fit_transform(X_test.iloc[:, 8])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7b9d736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:,:8] = sc.fit_transform(X_train.iloc[:,:8])\n",
    "X_test.iloc[:,:8] = sc.transform(X_test.iloc[:,:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "488f08dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 3ms/step - loss: 0.6544 - accuracy: 0.8269\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.8269\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.8269\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.8269\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.8269\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.8269\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8269\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8269\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8269\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8269\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8269\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8269\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8269\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8269\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8269\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8269\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8269\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8205\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8301\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8301\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8269\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8301\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8365\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8462\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8590\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8718\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8782\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.8846\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8910\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9006\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9006\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.9006\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9038\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9071\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9135\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.9135\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9103\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9103\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9071\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9071\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9071\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9135\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9135\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9135\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9103\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9103\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9135\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9135\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9135\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9167\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9199\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9263\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9231\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9263\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9263\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9263\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9263\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9231\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9231\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9327\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9327\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9327\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9327\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9359\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9327\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9359\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9359\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9359\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9359\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9359\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9359\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9391\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9391\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9391\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9391\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9391\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9327\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9391\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9391\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9327\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9359\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9359\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9359\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9359\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9359\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9327\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9359\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9359\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9359\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9327\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9327\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9327\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9327\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9327\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9359\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9327\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9327\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eeecf3b490>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, batch_size = 26, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "afd2686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "[[85  7]\n",
      " [ 8  4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9326923076923077"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final = ann.predict(X_test)\n",
    "y_pred_final = (y_pred_final > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89216b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f79b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81752c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a6a82ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 1s 5ms/step - loss: 0.6498 - accuracy: 0.7564\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.8269\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.8269\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8269\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8269\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3075 - accuracy: 0.8237\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8365\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.8397\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.8429\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.8462\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2320 - accuracy: 0.8462\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.8654\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.8686\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.8718\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.8846\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 0.8974\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9167\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9167\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1857 - accuracy: 0.9295\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9231\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9391\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.9199\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1600 - accuracy: 0.9359\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9359\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1eee9539040>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv1D(filters=32, kernel_size=4, activation='relu', input_shape=[12, 1]))\n",
    "#cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "#cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "#cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=12, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.fit(X_train,y_train, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d9dcab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b99ebd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1a2f3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  6]\n",
      " [ 6  6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8846153846153846"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f18588",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_lbwo = pd.read_excel('C://Users//S1130863//Downloads/diss/testing_lbwo.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
